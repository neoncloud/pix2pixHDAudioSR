{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os, sys\n",
    "import numpy as np\n",
    "parent_dir = os.path.abspath('../')\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "from torch.nn.functional import pad,fold\n",
    "from util.util import kbdwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(start=0, end=16,step=1, dtype=torch.float64)\n",
    "exp = torch.exp(-2j*torch.pi/16*(torch.arange(start=0, end=16//4,step=1, dtype=torch.float64)+1/8))\n",
    "print(exp)\n",
    "a = (a[...,:16//2:2]-a[...,1+16//2::2].flip(-1)) - 1j*(a[...,16//2::2]-a[...,1:16//2:2].flip(-1))\n",
    "print(a)\n",
    "a = a*exp\n",
    "a = torch.fft.fft(a)\n",
    "a = a*exp\n",
    "print(a)\n",
    "a = 2/torch.sqrt(torch.tensor(16))*torch.view_as_real(a)\n",
    "print(a)\n",
    "a[...,1] = -a[...,1].flip(-1)\n",
    "a = a.flatten(-2)\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(start=0, end=16,step=1, dtype=torch.float64)\n",
    "print(a[...,:16//2:2])\n",
    "print(a[...,1:16//2:2])\n",
    "print(a[...,16//2::2])\n",
    "print(a[...,1+16//2::2])\n",
    "b = torch.tensor([[1,2,3,4],[5,6,7,8]])\n",
    "print(b.transpose(-1,-2).flatten(-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(start=0, end=16,step=1, dtype=torch.float64)\n",
    "print(a)\n",
    "a = a.unfold(-1,2,2)\n",
    "print(a)\n",
    "a[...,1] = a[...,1].flip(-1)\n",
    "print(a)\n",
    "a = a.unfold(-2,4,4)\n",
    "print(a)\n",
    "#a = a[...,0]-a[...,1] + 1j*(a[...,2]-a[...,3])\n",
    "print(a[0,0,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.stack((torch.arange(start=32//2-1, end=0, step=-2, dtype=torch.long),torch.arange(start=0, end=32//2, step=2, dtype=torch.long)),dim=0)\n",
    "print(c.shape)\n",
    "print(c.flatten(-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.tensor([4,5,6,7])\n",
    "a = torch.tensor([0,1,2,3])\n",
    "c = torch.stack((a,b),-1).T.flatten(-2)\n",
    "d =  torch.stack((c,-c.flip(-1)),dim=-1).flatten(-2)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(start=0, end=16,step=1, dtype=torch.float64)\n",
    "# a = a.unfold(-1,2,2)\n",
    "# a.transpose(-1,-2).flatten(-2).roll(8)\n",
    "# a[...,-1] = a[...,-1].flip(-1)\n",
    "# a = a.unfold(0,4,4)\n",
    "print(a.roll(4,dims=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1,2,3,4],[5,6,7,8]])\n",
    "a.flatten(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_scatter import scatter\n",
    "class FastMDCT4(torch.nn.Module):\n",
    "    def __init__(self, n_fft=2048, hop_length=None, win_length=None, window=None, center=True, pad_mode='constant', device='cuda') -> None:\n",
    "        super().__init__()\n",
    "        self.n_fft = n_fft\n",
    "        self.pad_mode = pad_mode\n",
    "        self.device = device\n",
    "        self.hop_length = hop_length\n",
    "        self.center = center\n",
    "\n",
    "        # making window\n",
    "        if window is None:\n",
    "            window = torch.ones\n",
    "        if callable(window):\n",
    "            self.win_length = int(win_length)\n",
    "            self.window = window(self.win_length).to(self.device)\n",
    "        else:\n",
    "            self.window = window.to(self.device)\n",
    "            self.win_length = len(window)\n",
    "\n",
    "        assert self.win_length <= self.n_fft, 'Window lenth %d should be no more than fft length %d'%(self.win_length, self.n_fft)\n",
    "        assert self.hop_length <= self.win_length, 'You hopped more than one frame'\n",
    "        \n",
    "        self.idx = torch.stack((\n",
    "            torch.arange(\n",
    "            start=0, end=n_fft//2, step=2, dtype=torch.long),\n",
    "            torch.arange(\n",
    "            start=n_fft-1, end=n_fft//2, step=-2, dtype=torch.long),\n",
    "            torch.arange(\n",
    "            start=n_fft//2, end=n_fft, step=2, dtype=torch.long),\n",
    "            torch.arange(\n",
    "            start=n_fft//2-1, end=0, step=-2, dtype=torch.long)\n",
    "        ),dim=0)\n",
    "        \n",
    "        self.sqrtN = torch.sqrt(torch.tensor([self.n_fft],device=self.device))\n",
    "        self.post_exp = torch.exp(-2j*torch.pi/self.n_fft*(torch.arange(start=0,\n",
    "                             end=self.n_fft//4, step=1, dtype=torch.float32)+1/8)).to(self.device)\n",
    "\n",
    "        self.pre_exp = self.make_pre_exp()*self.window.to(self.device)\n",
    "        self.index = self.make_index()\n",
    "        \n",
    "    def make_pre_exp(self):\n",
    "        sgn = torch.ones(1,self.n_fft, dtype=torch.complex64, device=self.device)\n",
    "        # Shift for Time-Domain Aliasing Cancellation (TDAC)\n",
    "        sgn[...,-self.n_fft//4:] *= -1\n",
    "        sgn = sgn.roll(self.n_fft//4,dims=-1)\n",
    "        sgn[...,self.idx[0]] *= self.post_exp\n",
    "        sgn[...,self.idx[1]] *= -self.post_exp\n",
    "        sgn[...,self.idx[2]] *= -1j*self.post_exp\n",
    "        sgn[...,self.idx[3]] *= 1j*self.post_exp\n",
    "        return sgn.roll(-self.n_fft//4,dims=-1).to(self.device).contiguous()\n",
    "\n",
    "    def make_index(self):\n",
    "        i = torch.arange(start=0, end=self.n_fft, step=1, dtype=torch.long, device=self.device)\n",
    "        i = i.roll(self.n_fft//4,dims=-1)\n",
    "        idx_ = torch.stack([i[self.idx[0]], i[self.idx[1]], i[self.idx[2]], i[self.idx[3]]],dim=1)\n",
    "        index = torch.zeros(1,self.n_fft,device=self.device, dtype=torch.long)\n",
    "        for i in torch.arange(0,self.n_fft//4,dtype=torch.long):\n",
    "          index[...,idx_[i]]=i\n",
    "        return index.squeeze().contiguous()\n",
    "\n",
    "    def forward(self, signal, return_frames:bool=False):\n",
    "        # Pad the signal to a proper length\n",
    "        signal_len = int(len(signal))\n",
    "        start_pad = 0\n",
    "        # Pad the signal so that the t-th frame is centered at time t * hop_length. Otherwise, the t-th frame begins at time t * hop_length.\n",
    "        if self.center:\n",
    "            start_pad = self.hop_length\n",
    "        additional_len = signal_len%self.hop_length\n",
    "        end_pad = start_pad\n",
    "        if additional_len:\n",
    "            end_pad = start_pad + self.hop_length - additional_len\n",
    "        signal = pad(signal, (start_pad,end_pad), mode=self.pad_mode)\n",
    "\n",
    "        # Slice the signal with overlapping\n",
    "        signal = signal.unfold(dimension=-1, size=self.win_length, step=self.hop_length)\n",
    "\n",
    "        # # Apply windows to each pieces\n",
    "        # signal = torch.mul(signal.to(self.device), self.window.to(self.device))\n",
    "        # if return_frames:\n",
    "        #     frames = signal.clone()\n",
    "        # else:\n",
    "        #     frames = torch.empty(1)\n",
    "\n",
    "        # # Pad zeros for DCT\n",
    "        # if self.n_fft > self.win_length:\n",
    "        #     signal = pad(signal, (0, self.n_fft-self.win_length), mode='constant')\n",
    "\n",
    "\n",
    "        # Black magik here: fully exploiting the symmetric property of O2FFT,\n",
    "        # by rearranging the original real sequence into \n",
    "        # the real and imag part of a new sequence with half of the length.\n",
    "        # pre-twiddle\n",
    "        signal = signal*self.pre_exp\n",
    "        signal = scatter(signal, self.index, dim=-1, reduce='sum')\n",
    "        signal = torch.fft.fft(signal,dim=-1)\n",
    "        # post-twiddle\n",
    "        signal = torch.conj_physical(signal*self.post_exp)\n",
    "        # rearranging\n",
    "        signal = torch.view_as_real(signal)\n",
    "        signal[...,1] = signal[...,1].flip(-1)\n",
    "        signal = signal.flatten(-2)\n",
    "\n",
    "        return signal, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastIMDCT4(torch.nn.Module):\n",
    "    def __init__(self, n_fft=2048, hop_length=None, win_length=None, window=None, center=True, pad_mode='constant', out_length=None,device='cuda') -> None:\n",
    "        super().__init__()\n",
    "        self.n_fft = n_fft\n",
    "        self.pad_mode = pad_mode\n",
    "        self.device = device\n",
    "        self.hop_length = hop_length\n",
    "        self.center = center\n",
    "        self.out_length = out_length\n",
    "\n",
    "        # making window\n",
    "        if window is None:\n",
    "            window = torch.ones\n",
    "        if callable(window):\n",
    "            self.win_length = int(win_length)\n",
    "            self.window = window(self.win_length).to(self.device)\n",
    "        else:\n",
    "            self.window = window.to(self.device)\n",
    "            self.win_length = len(window)\n",
    "\n",
    "        assert self.win_length <= self.n_fft, 'Window lenth %d should be no more than fft length %d'%(self.win_length, self.n_fft)\n",
    "        assert self.hop_length <= self.win_length, 'You hopped more than one frame'\n",
    "        \n",
    "        self.exp = torch.exp(-2j*torch.pi/self.n_fft*(torch.arange(start=0,\n",
    "                             end=self.n_fft//4, step=1, dtype=torch.float64)+1/8)).to(self.device)\n",
    "\n",
    "    def forward(self, signal, return_frames:bool=False):\n",
    "        assert signal.dim() == 3, 'Only tensors shaped in BHW are supported, got tensor of shape %s'%(str(signal.size()))\n",
    "        assert signal.size()[-1] == self.n_fft//2, 'The last dim of input tensor should match the n_fft. Expected %d ,got %d'%(self.n_fft, signal.size()[-1])\n",
    "        \n",
    "        signal = signal.to(self.device)\n",
    "        # Inverse transform at the last dim\n",
    "        print(signal.shape)\n",
    "        signal = signal.unfold(-1,2,2)\n",
    "        signal[...,1] = signal[...,1].flip(-1)\n",
    "        signal = torch.view_as_complex(signal)\n",
    "\n",
    "        signal = self.exp*signal\n",
    "        signal = torch.fft.fft(signal)\n",
    "        signal = self.exp*signal\n",
    "\n",
    "        # [0+4j, 1+5j, 2+6j, 3+7j] -> [0,1,2,3,4,5,6,7] \n",
    "        signal = torch.view_as_real(signal).T.flatten(-2)\n",
    "        # [0,1,2,3,4,5,6,7]  -> [[0,-7], [1,-6], ..., [7,0]]\n",
    "        signal = torch.stack((signal,-signal.flip(-1)),dim=-1)\n",
    "        # [0, -7,  1, -6,  2, -5,  3, -4,  4, -3,  5, -2,  6, -1,  7,  0]\n",
    "        # with overlap-add, these redundancy term will be cancelled\n",
    "        signal = signal.flatten(-2)\n",
    "\n",
    "        # Shift N/4 for Time-Domain Aliasing Cancellation (TDAC)\n",
    "        signal[...,0:self.n_fft//4] *= -1\n",
    "        signal = signal.roll(-self.n_fft//4,dims=-1)\n",
    "\n",
    "        # Remove padded zeros when doing dct\n",
    "        if self.n_fft > self.win_length:\n",
    "            signal = signal[...,:self.win_length]\n",
    "\n",
    "        # Apply windows to each pieces\n",
    "        signal = torch.mul(signal, self.window)\n",
    "        if return_frames:\n",
    "            frames = signal.clone()\n",
    "        else:\n",
    "            frames = torch.zeros(1)\n",
    "\n",
    "        # Overlapping adding by fold()\n",
    "        out_len = (signal.size()[-2]-1) * self.hop_length + self.win_length\n",
    "        signal = fold(signal.transpose_(-1,-2), kernel_size=(1,self.win_length), stride=(1,self.hop_length), output_size=(1,out_len))\n",
    "\n",
    "        if self.center:\n",
    "            # extract the middle part\n",
    "            signal = signal[..., self.win_length//2:-self.win_length//2]\n",
    "        signal = 4.0*signal / (self.n_fft)\n",
    "        signal = signal if self.out_length is None else signal[...,:self.out_length]\n",
    "        return signal, frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 512\n",
    "win=kbdwin(N).cuda()\n",
    "# mdct = FastMDCT4(n_fft=N, hop_length=N//2, win_length=N, window=win, center=True, device='cuda')\n",
    "# imdct = FastIMDCT4(n_fft=N, hop_length=N//2, win_length=N, window=win, center=True, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchaudio.functional as aF\n",
    "audio_path = '/home/neoncloud/VCTK-Corpus/wav48/p227/p227_003.wav'\n",
    "metadata = torchaudio.info(audio_path)\n",
    "print(metadata.num_frames)\n",
    "audio, fs = torchaudio.load(audio_path)\n",
    "K = 50000\n",
    "audio_seg = audio[...,K:130816+K].squeeze()\n",
    "print(audio_seg.mean())\n",
    "plt.plot(audio_seg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectro, _ = mdct(audio_seg.cuda().squeeze(0))\n",
    "spectro_ = aF.amplitude_to_DB((spectro.abs().permute(1,0) + 1e-4),20,1e-4,1).squeeze(0)\n",
    "print(spectro.size())\n",
    "print(spectro.device)\n",
    "sp_fig, sp_ax = plt.subplots()\n",
    "sp_ax.pcolormesh(spectro_.cpu().numpy(), cmap='PuBu_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction, _ = imdct(spectro.unsqueeze(0))\n",
    "err = (audio_seg.cpu().squeeze()[:130000] - reconstruction.squeeze().cpu()[:130000])**2\n",
    "print(reconstruction.mean())\n",
    "print(err.mean())\n",
    "plt.plot(reconstruction.cpu().squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.mdct import IMDCT4\n",
    "imdct_ = IMDCT4(n_fft=N, hop_length=N//2, win_length=N, window=win, center=True, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_, _ = imdct_(spectro.unsqueeze(0))\n",
    "err = (audio_seg.cpu().squeeze()[:130000] - reconstruction_.squeeze().cpu()[:130000])**2\n",
    "print(reconstruction_.mean())\n",
    "print(err.mean())\n",
    "plt.plot(reconstruction_.cpu().squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "from models.mdct import MDCT4\n",
    "N = 512\n",
    "mdct = MDCT4(n_fft=N, hop_length=N//2, win_length=N, window=win, center=True, device='cuda')\n",
    "fast_mdct = FastMDCT4(n_fft=N, hop_length=N//2, win_length=N, window=win, center=True, device='cuda')\n",
    "a = torch.randn(64,1,32512).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit for i in range(500): mdct(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit for i in range(500): fast_mdct(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 128, 128, 2])\n",
      "torch.Size([64, 1, 128, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(5.2814e+08, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A,_ = mdct(a)\n",
    "B,_ = fast_mdct(a)\n",
    "(A-B).pow(2).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 06:56:58) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b00873fea601b69fcf5d3add94a63c6af5238bf69cc8eee1c7de23e514528387"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
