{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os, sys\n",
    "import numpy as np\n",
    "parent_dir = os.path.abspath('../')\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "from torch.nn.functional import pad,fold\n",
    "from util.util import kbdwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(start=0, end=16,step=1, dtype=torch.float64)\n",
    "exp = torch.exp(-2j*torch.pi/16*(torch.arange(start=0, end=16//4,step=1, dtype=torch.float64)+1/8))\n",
    "print(exp)\n",
    "a = (a[...,:16//2:2]-a[...,1+16//2::2].flip(-1)) - 1j*(a[...,16//2::2]-a[...,1:16//2:2].flip(-1))\n",
    "print(a)\n",
    "a = a*exp\n",
    "a = torch.fft.fft(a)\n",
    "a = a*exp\n",
    "print(a)\n",
    "a = 2/torch.sqrt(torch.tensor(16))*torch.view_as_real(a)\n",
    "print(a)\n",
    "a[...,1] = -a[...,1].flip(-1)\n",
    "a = a.flatten(-2)\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(start=0, end=16,step=1, dtype=torch.float64)\n",
    "print(a[...,:16//2:2])\n",
    "print(a[...,1:16//2:2])\n",
    "print(a[...,16//2::2])\n",
    "print(a[...,1+16//2::2])\n",
    "b = torch.tensor([[1,2,3,4],[5,6,7,8]])\n",
    "print(b.transpose(-1,-2).flatten(-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(start=0, end=16,step=1, dtype=torch.float64)\n",
    "print(a)\n",
    "a = a.unfold(-1,2,2)\n",
    "print(a)\n",
    "a[...,1] = a[...,1].flip(-1)\n",
    "print(a)\n",
    "a = a.unfold(-2,4,4)\n",
    "print(a)\n",
    "#a = a[...,0]-a[...,1] + 1j*(a[...,2]-a[...,3])\n",
    "print(a[0,0,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.stack((torch.arange(start=32//2-1, end=0, step=-2, dtype=torch.long),torch.arange(start=0, end=32//2, step=2, dtype=torch.long)),dim=0)\n",
    "print(c.shape)\n",
    "print(c.flatten(-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.tensor([4,5,6,7])\n",
    "a = torch.tensor([0,1,2,3])\n",
    "c = torch.stack((a,b),-1).T.flatten(-2)\n",
    "d =  torch.stack((c,-c.flip(-1)),dim=-1).flatten(-2)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(start=0, end=16,step=1, dtype=torch.float64)\n",
    "# a = a.unfold(-1,2,2)\n",
    "# a.transpose(-1,-2).flatten(-2).roll(8)\n",
    "# a[...,-1] = a[...,-1].flip(-1)\n",
    "# a = a.unfold(0,4,4)\n",
    "print(a.roll(4,dims=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1,2,3,4],[5,6,7,8]])\n",
    "a.flatten(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_scatter import scatter\n",
    "from typing import Optional, Union, Callable\n",
    "from einops import rearrange\n",
    "import torch.autograd.profiler as profiler\n",
    "\n",
    "class FastMDCT4(torch.nn.Module):\n",
    "    def __init__(self, n_fft: Optional[int] = 2048, hop_length: Optional[int] = None, win_length: Optional[int] = None, window: Union[torch.Tensor, np.ndarray, list, Callable, None] = None, center: bool = True, pad_mode: str = 'constant', device: str = 'cuda') -> None:\n",
    "        super().__init__()\n",
    "        self.n_fft = n_fft\n",
    "        self.pad_mode = pad_mode\n",
    "        self.device = device\n",
    "        self.hop_length = hop_length\n",
    "        self.center = center\n",
    "\n",
    "        if callable(window):\n",
    "            self.win_length = int(win_length)\n",
    "            self.window = window(self.win_length).to(\n",
    "                device=self.device, dtype=torch.float64)\n",
    "        elif isinstance(window, torch.Tensor):\n",
    "            self.window = window.to(device=self.device, dtype=torch.float64)\n",
    "            self.win_length = len(window)\n",
    "        elif isinstance(window, np.ndarray) or isinstance(window, list):\n",
    "            self.window = torch.tensor(\n",
    "                window, device=self.device, dtype=torch.float64)\n",
    "            self.win_length = len(window)\n",
    "        elif window is None:\n",
    "            if win_length is not None:\n",
    "                self.win_length = win_length\n",
    "            elif n_fft is not None:\n",
    "                self.win_length = n_fft\n",
    "            else:\n",
    "                assert False, 'You should specify window length or n_fft'\n",
    "            self.window = torch.ones(\n",
    "                (self.win_length,), device=self.device, dtype=torch.float64)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        assert self.win_length <= self.n_fft, f'Window lenth {self.win_length} should be no more than fft length {self.n_fft}'\n",
    "        assert self.hop_length <= self.win_length, 'You hopped more than one frame'\n",
    "\n",
    "        self.idx = torch.stack((\n",
    "            torch.arange(\n",
    "                start=0, end=n_fft//2, step=2,\n",
    "                dtype=torch.long, device=self.device),\n",
    "            torch.arange(\n",
    "                start=n_fft-1, end=n_fft//2, step=-2,\n",
    "                dtype=torch.long, device=self.device),\n",
    "            torch.arange(\n",
    "                start=n_fft//2, end=n_fft, step=2,\n",
    "                dtype=torch.long, device=self.device),\n",
    "            torch.arange(\n",
    "                start=n_fft//2-1, end=0, step=-2,\n",
    "                dtype=torch.long, device=self.device)\n",
    "        ), dim=0)\n",
    "\n",
    "        # self.sqrtN = torch.sqrt(torch.tensor(\n",
    "        #     [self.n_fft], device=self.device, dtype=torch.float64))\n",
    "        self.post_exp = torch.exp(\n",
    "            -2j*torch.pi/self.n_fft*(\n",
    "                torch.arange(\n",
    "                    start=0,\n",
    "                    end=self.n_fft//4,\n",
    "                    step=1,\n",
    "                    dtype=torch.float64,\n",
    "                    device=self.device\n",
    "                )+1/8\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.pre_exp = (self.make_pre_exp()*self.window).to(torch.complex64)\n",
    "        self.post_exp = self.post_exp.to(torch.complex64)\n",
    "        # self.pre_idx = self.make_pre_idx()\n",
    "        self.post_idx = self.make_post_idx()\n",
    "        self.idx = self.idx.clone().mT.roll(self.n_fft//8,0).contiguous()\n",
    "        self.kernel = self.pre_exp[..., self.idx].permute(1,0,2).contiguous()\n",
    "\n",
    "    def make_pre_exp(self):\n",
    "        sgn = torch.ones(1, self.n_fft, dtype=torch.complex128,\n",
    "                         device=self.device)\n",
    "        # Shift for Time-Domain Aliasing Cancellation (TDAC)\n",
    "        sgn[..., -self.n_fft//4:] *= -1\n",
    "        sgn = sgn.roll(self.n_fft//4, dims=-1)\n",
    "        sgn[..., self.idx[0]] *= self.post_exp\n",
    "        sgn[..., self.idx[1]] *= -self.post_exp\n",
    "        sgn[..., self.idx[2]] *= -1j*self.post_exp\n",
    "        sgn[..., self.idx[3]] *= 1j*self.post_exp\n",
    "        return sgn.roll(-self.n_fft//4, dims=-1).to(self.device).contiguous()\n",
    "\n",
    "    # def make_pre_idx(self):\n",
    "    #     i = torch.arange(start=0, end=self.n_fft, step=1,\n",
    "    #                      dtype=torch.long, device=self.device)\n",
    "    #     i = i.roll(self.n_fft//4, dims=-1)\n",
    "    #     idx_ = torch.stack([i[self.idx[0]], i[self.idx[1]],\n",
    "    #                        i[self.idx[2]], i[self.idx[3]]], dim=1)\n",
    "    #     index = torch.zeros(\n",
    "    #         1, self.n_fft, device=self.device, dtype=torch.long)\n",
    "    #     for i in torch.arange(0, self.n_fft//4, dtype=torch.long):\n",
    "    #       index[..., idx_[i]] = i\n",
    "    #     return index.squeeze().contiguous()\n",
    "\n",
    "    def make_post_idx(self):\n",
    "        idx = torch.arange(self.n_fft//2, dtype=torch.long,\n",
    "                           device=self.device).reshape(-1, 2)\n",
    "        idx[:, 1] = idx[:, 1].flip(-1)\n",
    "        return idx.flatten()\n",
    "\n",
    "    def forward(self, signal: torch.tensor, return_frames: bool = False):\n",
    "        if signal.dim() == 2: # B T (mono)\n",
    "            signal = signal[:, None, :]\n",
    "        elif signal.dim() == 3: # B C T (stereo)\n",
    "            pass\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # Pad the signal to a proper length\n",
    "        B, C, T = signal.shape\n",
    "        start_pad = 0\n",
    "        # Pad the signal so that the t-th frame is centered at time t * hop_length. Otherwise, the t-th frame begins at time t * hop_length.\n",
    "        if self.center:\n",
    "            start_pad = self.hop_length\n",
    "        additional_len = T % self.hop_length\n",
    "        end_pad = start_pad\n",
    "        if additional_len:\n",
    "            end_pad = start_pad + self.hop_length - additional_len\n",
    "        signal = pad(signal, (start_pad, end_pad), mode=self.pad_mode)\n",
    "\n",
    "        # Slice the signal with overlapping\n",
    "        signal = signal.unfold(dimension=-1, size=self.win_length, step=self.hop_length)\n",
    "        # B C T -> B C N t\n",
    "        B,C,N,t = signal.shape\n",
    "        # signal_1 = signal.clone()*self.pre_exp\n",
    "        # signal_1 = scatter(signal_1, self.pre_idx, dim=-1, reduce='sum')\n",
    "\n",
    "        # Black magik here: fully exploiting the symmetric property of O2FFT,\n",
    "        # by rearranging the original real sequence into\n",
    "        # the real and imag part of a new sequence with half of the length.\n",
    "        # pre-twiddle\n",
    "        # signal = signal[..., self.idx]\n",
    "        signal = torch.gather(signal[...,None].expand(-1, -1, -1, -1, self.n_fft//4), -2, self.idx[None, None, None,...].expand(B, C, N, -1, -1))\n",
    "        signal = rearrange(signal, 'B C N t n -> (B C N) t n')\n",
    "        signal = torch.nn.functional.conv1d(\n",
    "            input=signal.to(torch.complex64),\n",
    "            weight=self.kernel,\n",
    "            stride=1,\n",
    "            groups=self.n_fft//4\n",
    "        )\n",
    "        signal = torch.fft.fft(signal[...,0], dim=-1)\n",
    "        \n",
    "        # post-twiddle\n",
    "        signal = torch.conj_physical(signal*self.post_exp)\n",
    "        # rearranging\n",
    "        signal = torch.view_as_real(signal)\n",
    "        signal = signal.view(B*C*N, -1)[..., self.post_idx]\n",
    "        signal = rearrange(signal, '(B C N) t -> B C N t', B=B, C=C)\n",
    "\n",
    "        return signal, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmdct = FastMDCT4(n_fft=32, hop_length=32//2, win_length=32, window=None, center=True, device='cuda')\n",
    "# print(fmdct.idx)\n",
    "# print(fmdct.pre_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = fmdct.idx.cpu()\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = torch.arange(0,32).float().repeat(2,1)\n",
    "print(signal.shape)\n",
    "exp = torch.ones(1,32)*torch.tensor([1,2,3,4]).repeat(8)\n",
    "signal *= exp.float()\n",
    "print(signal)\n",
    "b = torch.gather(signal[...,None].expand(-1, -1 ,8), -2, idx[None,...].expand(2,-1,-1))\n",
    "print(b)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_idx = fmdct.post_idx.cpu()\n",
    "signal = post_idx.clone().reshape(-1,2).float()\n",
    "print(post_idx)\n",
    "o = torch.zeros((1,16)).float().scatter_(1, post_idx[None,...], signal.view(1,-1))\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = torch.arange(0,32).repeat(2,1)\n",
    "exp = torch.ones(1,32)*torch.tensor([1,2,3,4]).repeat(8)\n",
    "print(signal)\n",
    "print(exp.shape)\n",
    "signal = scatter(signal*exp, fmdct.pre_idx.cpu(), dim=-1, reduce='sum')\n",
    "print(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = torch.arange(0,32).repeat(2,1)\n",
    "idx = fmdct.idx.mT.cpu().roll(4,0)\n",
    "print(idx.shape)\n",
    "k = exp[...,idx].permute(1,0,2)\n",
    "print(k.shape)\n",
    "o = torch.nn.functional.conv1d(signal[...,idx].float(), k, stride=1, groups=8)\n",
    "# o = o[:,torch.LongTensor([4, 3, 5, 2, 6, 1, 7, 0]),:]\n",
    "#                           4  5  6  7  0  1  2  3\n",
    "print(o)\n",
    "print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastIMDCT4(torch.nn.Module):\n",
    "    def __init__(self, n_fft: Optional[int] = 2048, hop_length: Optional[int] = None, win_length: Optional[int] = None, window: Union[torch.Tensor, np.ndarray, list, Callable, None] = None, center: bool = True, pad_mode: str = 'constant', out_length: Optional[int] = None, device: str = 'cuda') -> None:\n",
    "        super().__init__()\n",
    "        self.n_fft = n_fft\n",
    "        self.pad_mode = pad_mode\n",
    "        self.device = device\n",
    "        self.hop_length = hop_length\n",
    "        self.center = center\n",
    "        self.out_length = out_length\n",
    "\n",
    "        if callable(window):\n",
    "            self.win_length = int(win_length)\n",
    "            self.window = window(self.win_length).to(\n",
    "                device=self.device, dtype=torch.float64)\n",
    "        elif isinstance(window, torch.Tensor):\n",
    "            self.window = window.to(device=self.device, dtype=torch.float64)\n",
    "            self.win_length = len(window)\n",
    "        elif isinstance(window, np.ndarray) or isinstance(window, list):\n",
    "            self.window = torch.tensor(\n",
    "                window, device=self.device, dtype=torch.float64)\n",
    "            self.win_length = len(window)\n",
    "        elif isinstance(window, None):\n",
    "            if win_length is not None:\n",
    "                self.win_length = win_length\n",
    "            elif n_fft is not None:\n",
    "                self.win_length = n_fft\n",
    "            else:\n",
    "                assert False, 'You should specify window length or n_fft'\n",
    "            self.window = torch.ones(\n",
    "                (self.win_length,), device=self.device, dtype=torch.float64)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        assert self.win_length <= self.n_fft, f'Window lenth {self.win_length} should be no more than fft length {self.n_fft}'\n",
    "        assert self.hop_length <= self.win_length, 'You hopped more than one frame'\n",
    "\n",
    "        self.exp = torch.exp(\n",
    "            -2j*torch.pi/self.n_fft*(\n",
    "                torch.arange(\n",
    "                    start=0,\n",
    "                    end=self.n_fft//4,\n",
    "                    step=1,\n",
    "                    dtype=torch.float32,\n",
    "                    device=self.device\n",
    "                )+1/8\n",
    "            )\n",
    "        ).contiguous()\n",
    "        self.pre_idx = self.make_pre_idx()\n",
    "        self.post_idx = self.make_post_index()\n",
    "        #self.sgn = self.make_sign()\n",
    "        self.window = (4.0*self.make_sign()*self.window/self.n_fft).to(torch.float32).contiguous()\n",
    "\n",
    "    def make_pre_idx(self):\n",
    "        a = torch.arange(self.n_fft//2, dtype=torch.long,\n",
    "                         device=self.device).unfold(-1, 2, 2)\n",
    "        return torch.stack((a[..., 0], a[..., 1].flip(-1)), dim=-1).contiguous()\n",
    "\n",
    "    def make_post_index(self):\n",
    "        a = torch.arange(0, self.n_fft//2, 2,\n",
    "                         dtype=torch.long, device=self.device)\n",
    "        b = torch.arange(self.n_fft//2-1, 0, -2,\n",
    "                         dtype=torch.long, device=self.device)\n",
    "        idx = torch.empty((self.n_fft,), dtype=torch.long, device=self.device)\n",
    "        idx[0:self.n_fft//2:2] = a\n",
    "        idx[1:self.n_fft//2:2] = b\n",
    "        idx[self.n_fft//2:] = idx[:self.n_fft//2].flip(0)\n",
    "        return idx.roll(-self.n_fft//4).contiguous()\n",
    "\n",
    "    def make_sign(self):\n",
    "        sign = torch.ones((self.n_fft,), device=self.device,\n",
    "                          dtype=torch.float64)\n",
    "        sign[1::2] *= -1\n",
    "        sign[..., 0:self.n_fft//4] *= -1\n",
    "        return sign.roll(-self.n_fft//4).contiguous()\n",
    "\n",
    "    def forward(self, signal: torch.Tensor, return_frames: bool = False):\n",
    "        assert signal.dim(\n",
    "        ) <= 4, f'Only tensors shaped in BHW or BCHW are supported, got tensor of shape {signal.shape}'\n",
    "        assert signal.shape[\n",
    "            -1] == self.n_fft//2, f'The last dim of input tensor should match the n_fft. Expected {self.n_fft}, got {signal.shape[-1]}'\n",
    "\n",
    "        if signal.dim() == 4:\n",
    "            C = signal.shape[1]\n",
    "            signal = rearrange(signal, 'B C T N -> (B C) T N')\n",
    "        else:\n",
    "            C = 1\n",
    "\n",
    "        signal = signal.to(self.device)\n",
    "        # # Inverse transform at the last dim\n",
    "        signal = torch.view_as_complex(signal[..., self.pre_idx])\n",
    "\n",
    "        signal = self.exp*signal\n",
    "        signal = torch.fft.fft(signal)\n",
    "        signal = self.exp*signal\n",
    "\n",
    "        # [0+4j, 1+5j, 2+6j, 3+7j] -> [2,-5, 3, -4, 4, -3, 5, -2, 6, -1, 7, 0, 0, 7, -1, 6]\n",
    "        signal = torch.view_as_real(signal).flatten(-2)[..., self.post_idx]\n",
    "\n",
    "        # Apply windows to each pieces\n",
    "        signal = self.window*signal\n",
    "        if return_frames:\n",
    "            frames = signal.clone()\n",
    "        else:\n",
    "            frames = torch.empty(1)\n",
    "\n",
    "        # Overlapping adding by fold()\n",
    "        out_len = (signal.shape[-2]-1) * self.hop_length + self.win_length\n",
    "        signal = fold(signal.mT, kernel_size=(1, self.win_length),\n",
    "                      stride=(1, self.hop_length), output_size=(1, out_len))\n",
    "\n",
    "        if self.center:  # extract the middle part\n",
    "            signal = signal[..., self.win_length//2:-self.win_length//2]\n",
    "        if self.out_length is not None:\n",
    "            signal = signal[..., :self.out_length]\n",
    "        # signal = 4.0*signal / (self.n_fft)\n",
    "        if C != 1:\n",
    "            signal = rearrange(signal, '(B C) T N-> B C T N')\n",
    "        return signal, frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.arange(0,32,2)\n",
    "print(b)\n",
    "a = torch.arange(16).unfold(-1,2,2)\n",
    "a = torch.stack((a[..., 0], a[...,1].flip(-1)), dim=-1)\n",
    "print(b[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([0+4j, 1+5j, 2+6j, 3+7j])\n",
    "a = torch.view_as_real(a).flatten()\n",
    "print(a)\n",
    "# [0, -7,  1, -6,  2, -5,  3, -4,  4, -3,  5, -2,  6, -1,  7,  0]\n",
    "#b = torch.tensor([[0,15],[7,8],[2,13],[5,10],[4,11],[3,12],[6,9],[1,14]])\n",
    "b = torch.LongTensor([0,7,2,5,4,3,6,1,1,6,3,4,5,2,7,0])\n",
    "c = a[b].roll(-4)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft = 16\n",
    "a = torch.arange(0,n_fft//2,2)\n",
    "b = torch.arange(n_fft//2-1,0,-2)\n",
    "c = torch.empty((n_fft,))\n",
    "c[0:n_fft//2:2] = a\n",
    "c[1:n_fft//2:2] = b\n",
    "c[n_fft//2:] = c[:n_fft//2].flip(0)\n",
    "c = c.roll(-n_fft//4)\n",
    "c = c.to(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([0+4j, 1+5j, 2+6j, 3+7j])\n",
    "a = torch.view_as_real(a).flatten()\n",
    "print(a[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([0, -7,  1, -6,  2, -5,  3, -4,  4, -3,  5, -2,  6, -1,  7,  0])\n",
    "a[...,0:n_fft//4] *= -1\n",
    "a = a.roll(-n_fft//4,dims=-1)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.ones((n_fft))\n",
    "b[1::2] *= -1\n",
    "b[...,0:n_fft//4] *= -1\n",
    "b = b.roll(-n_fft//4)\n",
    "print(a[c]*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 512\n",
    "win=kbdwin(N).cuda()\n",
    "# mdct = FastMDCT4(n_fft=N, hop_length=N//2, win_length=N, window=win, center=True, device='cuda')\n",
    "# imdct = FastIMDCT4(n_fft=N, hop_length=N//2, win_length=N, window=win, center=True, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchaudio.functional as aF\n",
    "audio_path = '/home/neoncloud/pix2pixHDAudioSR/test/test.wav'\n",
    "metadata = torchaudio.info(audio_path)\n",
    "print(metadata.num_frames)\n",
    "audio, fs = torchaudio.load(audio_path)\n",
    "K = 50000\n",
    "audio_seg = audio[...,K:130816+K].squeeze()\n",
    "print(audio_seg.shape)\n",
    "plt.plot(audio_seg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_seg = torch.stack([audio_seg]*16)\n",
    "spectro, _ = fast_mdct(audio_seg.cuda().squeeze(0))\n",
    "# spectro_ = aF.amplitude_to_DB((spectro.abs().permute(1,0) + 1e-4),20,1e-4,1).squeeze(0)\n",
    "print(spectro.size())\n",
    "print(spectro.device)\n",
    "sp_fig, sp_ax = plt.subplots()\n",
    "sp_ax.pcolormesh(spectro[0].cpu().numpy(), cmap='PuBu_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction, _ = imdct(spectro)\n",
    "err = (audio_seg.cpu().squeeze()[:130000] - reconstruction.squeeze().cpu()[:130000])**2\n",
    "print(reconstruction.mean())\n",
    "print(err.mean())\n",
    "plt.plot(reconstruction.mean(0).cpu().squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction, _ = fast_imdct(spectro)\n",
    "err = (audio_seg.cpu().squeeze()[:,:130000] - reconstruction.squeeze().cpu()[:,:130000])\n",
    "print(reconstruction.mean())\n",
    "print(err.mean())\n",
    "plt.plot(err.mean(1).cpu().squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.mdct import IMDCT4\n",
    "imdct_ = IMDCT4(n_fft=N, hop_length=N//2, win_length=N, window=win, center=True, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_, _ = imdct_(spectro.unsqueeze(0))\n",
    "err = (audio_seg.cpu().squeeze()[:130000] - reconstruction_.squeeze().cpu()[:130000])**2\n",
    "print(reconstruction_.mean())\n",
    "print(err.mean())\n",
    "plt.plot(reconstruction_.cpu().squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "from models.mdct import MDCT4, IMDCT4\n",
    "N = 512\n",
    "mdct = MDCT4(n_fft=N, hop_length=N//2, win_length=N, window=win, center=True, device='cuda')\n",
    "fast_mdct = FastMDCT4(n_fft=N, hop_length=N//2, win_length=N, window=win, center=True, device='cuda')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(64,32512).cuda()\n",
    "sig_1, sig_2 = fast_mdct(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_1.squeeze_()\n",
    "sig_2.squeeze_()\n",
    "(sig_2-sig_1).pow(2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fast_mdct.pre_idx.shape)\n",
    "print(fast_mdct.pre_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fast_mdct.idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r 20 -n 500 mdct(torch.randn(64,32512, device='cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r 20 -n 500 fast_mdct(torch.randn(64,32512, device='cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.9642e-06, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(64,32512).cuda()\n",
    "A,_ = mdct(a)\n",
    "B,_ = fast_mdct(a)\n",
    "B.squeeze_()\n",
    "(A-B).pow(2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdct = IMDCT4(n_fft=N, hop_length=N//2, win_length=N, window=win, center=True, device='cuda')\n",
    "fast_imdct = FastIMDCT4(n_fft=N, hop_length=N//2, win_length=N, window=win, center=True, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.5446e-08, device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a_, _ = imdct(A.squeeze())\n",
    "b_, _ = fast_imdct(A.squeeze())\n",
    "print((b_-a_).pow(2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(64,32512).cuda()\n",
    "k = 0\n",
    "for i in range(a.shape[0]):\n",
    "    A,_ = mdct(a[None,i,:].clone())\n",
    "    a_,_ = fast_imdct(A)\n",
    "    k += (a[i,:]-a_).pow(2)\n",
    "print(k.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(64,32512).cuda()\n",
    "A,_ = mdct(a)\n",
    "a_,_ = fast_imdct(A)\n",
    "(a-a_).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r 20 -n 500 imdct(torch.randn(64,128,256, device='cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r 20 -n 500 fast_imdct(torch.randn(64,128,256, device='cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(64,32512).cuda()\n",
    "fast_mdct(a)\n",
    "a = torch.randn(64,32512).cuda()\n",
    "with profiler.profile(with_stack=False, profile_memory=True) as prof:\n",
    "    A, _ = fast_mdct(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                       Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "---------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "           cudaLaunchKernel        23.32%     330.000us        23.32%     330.000us      15.714us           0 b           0 b           0 b           0 b            21  \n",
      "                aten::empty         6.22%      88.000us         6.22%      88.000us       8.000us           0 b           0 b      56.07 Mb      56.07 Mb            11  \n",
      "                aten::copy_         5.37%      76.000us        10.88%     154.000us      25.667us           0 b           0 b           0 b           0 b             6  \n",
      "                aten::slice         5.02%      71.000us         6.57%      93.000us      23.250us           0 b           0 b           0 b           0 b             4  \n",
      "         aten::_convolution         4.81%      68.000us        22.83%     323.000us     107.667us           0 b           0 b      12.00 Mb     -32.00 Mb             3  \n",
      "               aten::conv1d         4.45%      63.000us        44.88%     635.000us     635.000us           0 b         -16 b       8.00 Mb     -48.00 Mb             1  \n",
      "                  aten::mul         4.31%      61.000us         6.01%      85.000us      42.500us          16 b          16 b      16.00 Mb      16.00 Mb             2  \n",
      "             aten::_fft_c2c         4.31%      61.000us         6.01%      85.000us      85.000us           0 b           0 b       8.00 Mb      -8.00 Mb             1  \n",
      "                  aten::add         3.82%      54.000us         6.36%      90.000us      30.000us           0 b           0 b      24.00 Mb      24.00 Mb             3  \n",
      "    aten::_conv_depthwise2d         2.97%      42.000us        11.52%     163.000us      54.333us           0 b           0 b      12.00 Mb      -4.00 Kb             3  \n",
      "---------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.415ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages(group_by_stack_n=10).table(sort_by='self_cpu_time_total', row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(64,32512).cuda()\n",
    "A, _ = fast_mdct(a)\n",
    "a_ , _ = fast_imdct(A)\n",
    "with profiler.profile(with_stack=False, profile_memory=True) as prof2:\n",
    "    a_ , _ = fast_imdct(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                 aten::to        33.94%     298.000us        33.94%     298.000us     298.000us           0 b           0 b           0 b           0 b             1  \n",
      "         cudaLaunchKernel        16.74%     147.000us        16.74%     147.000us      18.375us           0 b           0 b           0 b           0 b             8  \n",
      "              aten::index         9.91%      87.000us        20.27%     178.000us      89.000us           0 b           0 b      24.00 Mb      24.00 Mb             2  \n",
      "           aten::_fft_c2c         5.69%      50.000us         8.43%      74.000us      74.000us           0 b           0 b       8.00 Mb      -8.00 Mb             1  \n",
      "                aten::mul         5.13%      45.000us         8.66%      76.000us      25.333us           0 b           0 b      32.00 Mb      32.00 Mb             3  \n",
      "             aten::col2im         3.19%      28.000us        15.60%     137.000us     137.000us           0 b           0 b      16.00 Mb     -16.00 Mb             1  \n",
      "              aten::empty         2.96%      26.000us         2.96%      26.000us       5.200us           4 b           4 b      48.00 Mb      48.00 Mb             5  \n",
      "            aten::reshape         2.73%      24.000us         4.78%      42.000us       8.400us           0 b           0 b           0 b           0 b             5  \n",
      "    aten::view_as_complex         2.73%      24.000us         2.73%      24.000us      24.000us           0 b           0 b           0 b           0 b             1  \n",
      "     aten::_reshape_alias         2.62%      23.000us         2.62%      23.000us       3.833us           0 b           0 b           0 b           0 b             6  \n",
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 878.000us\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof2.key_averages(group_by_stack_n=10).table(sort_by='self_cpu_time_total', row_limit=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b00873fea601b69fcf5d3add94a63c6af5238bf69cc8eee1c7de23e514528387"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
